1."Black-Box Dataset Ownership Verification via Backdoor Watermarking"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/10097580)
2."TensorClog: An Imperceptible Poisoning Attack on Deep Neural Network Applications"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/8668758)
3."Adversarial Examples Make Strong Poisons"    (https://www-webofscience-com.ledproxy2.uwindsor.ca/wos/woscc/full-record/WOS:000901616401001)
4."Towards Class-Oriented Poisoning Attacks Against Neural Networks"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9707042)
5."CLPA: Clean-Label Poisoning Availability Attacks Using Generative Adversarial Nets"    (https://www-webofscience-com.ledproxy2.uwindsor.ca/wos/woscc/full-record/WOS:000893639102021)
6."Boundary augment: A data augment method to defend poison attack"    (https://ietresearch-onlinelibrary-wiley-com.ledproxy2.uwindsor.ca/doi/10.1049/ipr2.12325)
7."Finding and removing Clever Hans: Using explanation methods to debug and improve deep models"    (https://www-sciencedirect-com.ledproxy2.uwindsor.ca/science/article/pii/S1566253521001573?via%3Dihub)
8."ACTSS: Input Detection Defense against Backdoor Attacks via Activation Subset Scanning"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9891900)
9."LIRA: Learnable, Imperceptible and Robust Backdoor Attacks"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9709953)
10."ProFlip: Targeted Trojan Attack with Progressive Bit Flips"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9709910)
11."Inconspicuous Data Augmentation Based Backdoor Attack on Deep Neural Networks"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9908113)
12."Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free"    (https://ieeexplore-ieee-org.ledproxy2.uwindsor.ca/document/9879256)


